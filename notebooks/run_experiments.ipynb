{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mijan103/workspace/pytorch_seed_rl'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change the Current working Directory\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = \"scaling_experiment/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_args = {\n",
    "    '--num_actors': [1,2,4,8,16],\n",
    "    '--num_prefetchers': [1,2,4,8],\n",
    "    '--num_env': [4,8,16,32,64,128],\n",
    "    '--batchsize_inference': [4,8,16,32,64,128,256,512,1024]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "keys, values = zip(*all_args.items())\n",
    "experiments = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "cleaned_experiments=[]\n",
    "for e in experiments:\n",
    "    if (e['--batchsize_inference'] <= (e['--num_actors'] * e['--num_env'])/2) and (e['--num_prefetchers'] <= e['--num_actors']):        \n",
    "            cleaned_experiments.append(e)\n",
    "\n",
    "len(cleaned_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_strings = []\n",
    "for e in cleaned_experiments:\n",
    "    exp_input = ' '.join([str(k + ' ' + str(v)) for k,v in e.items()])\n",
    "    exp_name = \"_\".join(['a', str(e['--num_actors']).zfill(2),\n",
    "     'p', str(e['--num_prefetchers']).zfill(1),\n",
    "     'n', str(e['--num_env']).zfill(3),\n",
    "     'b', str(e['--batchsize_inference']).zfill(3)])\n",
    "    \n",
    "    input_str = ' '.join([str(experiment_dir +'/' + exp_name)] + [str(k + ' ' + str(v)) for k,v in e.items()])\n",
    "    experiment_strings.append(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "1 callers spawned, awaiting start.\n",
      "csv logs will be saved at /home/mijan103/logs/pytorch_seed_rl/a_01_p_1_n_008_b_004/csv\n",
      "Caller loops started.\n",
      "Loop started. You can interupt using strg+c.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/mijan103/workspace/pytorch_seed_rl/pytorch_seed_rl/run.py\", line 276, in <module>\n",
      "    main(FLAGS)\n",
      "  File \"/home/mijan103/workspace/pytorch_seed_rl/pytorch_seed_rl/run.py\", line 268, in main\n",
      "    join=True\n",
      "  File \"/home/mijan103/.local/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 199, in spawn\n",
      "    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\n",
      "  File \"/home/mijan103/.local/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 157, in start_processes\n",
      "    while not context.join():\n",
      "  File \"/home/mijan103/.local/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\", line 77, in join\n",
      "    timeout=timeout,\n",
      "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 920, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.7/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "1 callers spawned, awaiting start.\n",
      "csv logs will be saved at /home/mijan103/logs/pytorch_seed_rl/a_01_p_1_n_016_b_004/csv\n",
      "Caller loops started.\n",
      "Loop started. You can interupt using strg+c.\n"
     ]
    }
   ],
   "source": [
    "for e_str in experiment_strings:\n",
    "    !python3 -m pytorch_seed_rl.run $e_str -R --gpu_ids 1 --total_steps 500000 --batchsize_training 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
