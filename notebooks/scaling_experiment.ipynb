{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/garg1/workspace/python/pytorch_seed_rl'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change the Current working Directory\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = '0'\n",
    "steps = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = \"scaling_experiment_final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_args = {\n",
    "    '--num_actors': [1,2,4],\n",
    "    '--num_envs': [4,8,16,32,64],\n",
    "    '--threads_store': [1,2,4,6,8,10,12],\n",
    "    '--threads_prefetch': [1,2],\n",
    "    '--threads_inference': [1,2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "keys, values = zip(*all_args.items())\n",
    "experiments = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "cleaned_experiments=[]\n",
    "for e in experiments:\n",
    "    if (e['--num_actors'] >= e['--threads_prefetch'] and\n",
    "        e['--num_actors'] >= e['--threads_inference'] and\n",
    "        e['--num_actors'] >= e['--threads_store']\n",
    "       ):\n",
    "        cleaned_experiments.append(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_experiments = [\n",
    "    {'--num_actors': 2, '--num_envs': 16,'--threads_store': 3, '--threads_prefetch': 1, '--threads_inference': 1},\n",
    "    {'--num_actors': 2, '--num_envs': 16,'--threads_store': 3, '--threads_prefetch': 2, '--threads_inference': 1},\n",
    "    \n",
    "    {'--num_actors': 2, '--num_envs': 32,'--threads_store': 3, '--threads_prefetch': 1, '--threads_inference': 1},\n",
    "    {'--num_actors': 2, '--num_envs': 32,'--threads_store': 3, '--threads_prefetch': 2, '--threads_inference': 1},\n",
    "    \n",
    "    {'--num_actors': 2, '--num_envs': 64,'--threads_store': 3, '--threads_prefetch': 1, '--threads_inference': 1},\n",
    "    {'--num_actors': 2, '--num_envs': 64,'--threads_store': 3, '--threads_prefetch': 2, '--threads_inference': 1},\n",
    "    \n",
    "    {'--num_actors': 4, '--num_envs': 16,'--threads_store': 3, '--threads_prefetch': 1, '--threads_inference': 1},\n",
    "    {'--num_actors': 4, '--num_envs': 16,'--threads_store': 3, '--threads_prefetch': 2, '--threads_inference': 1},\n",
    "    \n",
    "    {'--num_actors': 4, '--num_envs': 32,'--threads_store': 3, '--threads_prefetch': 1, '--threads_inference': 1},\n",
    "    {'--num_actors': 4, '--num_envs': 32,'--threads_store': 3, '--threads_prefetch': 2, '--threads_inference': 1},\n",
    "    \n",
    "    {'--num_actors': 4, '--num_envs': 64,'--threads_store': 3, '--threads_prefetch': 1, '--threads_inference': 1},\n",
    "    {'--num_actors': 4, '--num_envs': 64,'--threads_store': 3, '--threads_prefetch': 2, '--threads_inference': 1},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_strings = []\n",
    "for e in cleaned_experiments:\n",
    "    exp_input = ' '.join([str(k + ' ' + str(v)) for k,v in e.items()])\n",
    "    exp_name = \"_\".join(['a', str(e['--num_actors']).zfill(2),\n",
    "                         'p', str(e['--threads_prefetch']).zfill(1),\n",
    "                         'i', str(e['--threads_inference']).zfill(1),\n",
    "                         'n', str(e['--num_envs']).zfill(2),\n",
    "                         's', str(e['--threads_store']).zfill(2)\n",
    "                        ])\n",
    "    \n",
    "    input_str = ' '.join([str(experiment_dir +'/' + exp_name)] + [str(k + ' ' + str(v)) for k,v in e.items()])\n",
    "    experiment_strings.append(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "2 callers spawned, awaiting start.\n",
      "csv logs will be saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_02_p_1_i_1_n_16_s_03/csv\n",
      "Caller loops started.\n",
      "Loop started. You can interupt using strg+c.\n",
      "Final model saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_02_p_1_i_1_n_16_s_03/model/final_model.pt.\n",
      "Answering pending RPCs.\n",
      "[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
      "Joining processing threads.\n",
      "Write and empty log buffers.\n",
      "Empty queues.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "2 callers spawned, awaiting start.\n",
      "csv logs will be saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_02_p_2_i_1_n_16_s_03/csv\n",
      "Caller loops started.\n",
      "Loop started. You can interupt using strg+c.\n",
      "Final model saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_02_p_2_i_1_n_16_s_03/model/final_model.pt.\n",
      "Answering pending RPCs.\n",
      "[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
      "[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
      "Joining processing threads.\n",
      "Write and empty log buffers.\n",
      "Empty queues.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "2 callers spawned, awaiting start.\n",
      "csv logs will be saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_02_p_1_i_1_n_32_s_03/csv\n",
      "Caller loops started.\n",
      "Loop started. You can interupt using strg+c.\n",
      "Final model saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_02_p_1_i_1_n_32_s_03/model/final_model.pt.\n",
      "Answering pending RPCs.\n",
      "[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
      "Joining processing threads.\n",
      "Write and empty log buffers.\n",
      "Empty queues.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "2 callers spawned, awaiting start.\n",
      "csv logs will be saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_02_p_2_i_1_n_32_s_03/csv\n",
      "Caller loops started.\n",
      "Loop started. You can interupt using strg+c.\n",
      "Final model saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_02_p_2_i_1_n_32_s_03/model/final_model.pt.\n",
      "Answering pending RPCs.\n",
      "[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
      "[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
      "Joining processing threads.\n",
      "Write and empty log buffers.\n",
      "Empty queues.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "2 callers spawned, awaiting start.\n",
      "csv logs will be saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_02_p_1_i_1_n_64_s_03/csv\n",
      "Caller loops started.\n",
      "Loop started. You can interupt using strg+c.\n",
      "Final model saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_02_p_1_i_1_n_64_s_03/model/final_model.pt.\n",
      "Answering pending RPCs.\n",
      "[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
      "Joining processing threads.\n",
      "Write and empty log buffers.\n",
      "Empty queues.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "2 callers spawned, awaiting start.\n",
      "csv logs will be saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_02_p_2_i_1_n_64_s_03/csv\n",
      "Caller loops started.\n",
      "Loop started. You can interupt using strg+c.\n",
      "Final model saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_02_p_2_i_1_n_64_s_03/model/final_model.pt.\n",
      "Answering pending RPCs.\n",
      "[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
      "Joining processing threads.\n",
      "Write and empty log buffers.\n",
      "Empty queues.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "4 callers spawned, awaiting start.\n",
      "csv logs will be saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_04_p_1_i_1_n_16_s_03/csv\n",
      "Caller loops started.\n",
      "Loop started. You can interupt using strg+c.\n",
      "Final model saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_04_p_1_i_1_n_16_s_03/model/final_model.pt.\n",
      "Answering pending RPCs.\n",
      "[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
      "Joining processing threads.\n",
      "Write and empty log buffers.\n",
      "Empty queues.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "4 callers spawned, awaiting start.\n",
      "csv logs will be saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_04_p_2_i_1_n_16_s_03/csv\n",
      "Caller loops started.\n",
      "Loop started. You can interupt using strg+c.\n",
      "Final model saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_04_p_2_i_1_n_16_s_03/model/final_model.pt.\n",
      "Answering pending RPCs.\n",
      "[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
      "Joining processing threads.\n",
      "Write and empty log buffers.\n",
      "Empty queues.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "4 callers spawned, awaiting start.\n",
      "csv logs will be saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_04_p_1_i_1_n_32_s_03/csv\n",
      "Caller loops started.\n",
      "Loop started. You can interupt using strg+c.\n",
      "Final model saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_04_p_1_i_1_n_32_s_03/model/final_model.pt.\n",
      "Answering pending RPCs.\n",
      "[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
      "Joining processing threads.\n",
      "Write and empty log buffers.\n",
      "Empty queues.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "4 callers spawned, awaiting start.\n",
      "csv logs will be saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_04_p_2_i_1_n_32_s_03/csv\n",
      "Caller loops started.\n",
      "Loop started. You can interupt using strg+c.\n",
      "Final model saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_04_p_2_i_1_n_32_s_03/model/final_model.pt.\n",
      "Answering pending RPCs.\n",
      "[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
      "[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
      "Joining processing threads.\n",
      "Write and empty log buffers.\n",
      "Empty queues.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "4 callers spawned, awaiting start.\n",
      "csv logs will be saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_04_p_1_i_1_n_64_s_03/csv\n",
      "Caller loops started.\n",
      "Loop started. You can interupt using strg+c.\n",
      "Final model saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_04_p_1_i_1_n_64_s_03/model/final_model.pt.\n",
      "Answering pending RPCs.\n",
      "[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
      "Joining processing threads.\n",
      "Write and empty log buffers.\n",
      "Empty queues.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "RPC was initialized with the PROCESS_GROUP backend which is deprecated and slated to be removed and superseded by the TENSORPIPE backend. It is recommended to migrate to the TENSORPIPE backend.\n",
      "4 callers spawned, awaiting start.\n",
      "csv logs will be saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_04_p_2_i_1_n_64_s_03/csv\n",
      "Caller loops started.\n",
      "Loop started. You can interupt using strg+c.\n",
      "Final model saved at /home/garg1/logs/pytorch_seed_rl/scaling_experiment_final/a_04_p_2_i_1_n_64_s_03/model/final_model.pt.\n",
      "Answering pending RPCs.\n",
      "[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
      "[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\n",
      "Joining processing threads.\n",
      "Write and empty log buffers.\n",
      "Empty queues.\n"
     ]
    }
   ],
   "source": [
    "for e_str in experiment_strings:\n",
    "    !python3 -m pytorch_seed_rl.run $e_str --gpu_ids $GPU --total_steps $steps --checkpoint_interval 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
